# -*- coding: utf-8 -*-
"""MPAc290 3rd session.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dfNqaxQmPRpJx0gmMPwwj6vOVeOIy_sJ

Model

Regression

Optimization

EDA -- Exploratory Data Analysis
"""

import pandas as pd
url = 'https://raw.githubusercontent.com/ArashVafa/DESC624/master/bank_marketing_training'
bank_train = pd.read_csv(url)
bank_train.head(10)

bank_train['index'] = pd.Series(range(0,26874))

bank_train['days_since_previous'].plot(kind = 'hist')

import numpy as np
bank_train['days_since_previous'] = bank_train['days_since_previous'].replace({999: np.NaN})

bank_train['days_since_previous'].plot(kind = 'hist', title = 'histogram of data')

"""misleading values --> NaN, or median or mean or by random numbers


we change a distribution by changing its mean and std
"""

bank_train['education_numeric'] = bank_train['education']
dict_edu = {"education_numeric": {"illiterate": 0, "basic.4y": 4, "basic.6y": 6,     "basic.9y": 9, "high.school":12, "professional.course": 12, "university.degree":16, 'unknown': np.NaN}}
bank_train.replace(dict_edu, inplace = True)
bank_train

from scipy import stats
bank_train['age_z'] = stats.zscore(bank_train['age'])

bank_train

bank_train['age'].mean()

bank_train['age'].plot(kind = 'hist')

bank_train['age_z'].plot(kind = 'hist')

bank_train_outliers = bank_train.query('age_z > 3' or 'age_z < -3')

bank_train_sort = bank_train.sort_values(['age_z'], ascending = False)

bank_train_sort[['age', 'marital']].tail(n=15)

"""bar graphs with response overlay"""

crosstab_01 = pd.crosstab(bank_train['previous_outcome'], bank_train['response'])
crosstab_norm = crosstab_01.div(crosstab_01.sum(1), axis = 0)
crosstab_01.plot(kind='bar', stacked = True)

"""the following plot is the normalized version of the previous one."""

crosstab_norm.plot(kind='bar', stacked = True)

"""Hypothesis: there is a higher chance of yes if the previous outcome was success.

(we can perform a t-test to evaluate our hypothesis)

# contingency tables
"""

crosstab_01 = pd.crosstab(bank_train['previous_outcome'], bank_train['response'])

crosstab_02 = pd.crosstab(bank_train['response'], bank_train['previous_outcome'],)

round(crosstab_02.div(crosstab_02.sum(0),axis = 1)*100,1)

import numpy as np
import matplotlib.pyplot as plt

bt_age_y = bank_train[bank_train.response == 'yes']['age']
bt_age_n = bank_train[bank_train.response == 'no']['age']

plt.hist([bt_age_y,bt_age_n], bins = 20, stacked = True)

plt.show()

(n, bins, patches) = plt.hist([bt_age_y, bt_age_n], bins = 10, stacked = True)
n_table = np.column_stack((n[0], n[1]))
n_norm = n_table / n_table.sum(axis=1)[:, None]
ourbins = np.column_stack((bins[0:10], bins[1:11]))

p1 = plt.bar(x = ourbins[:,0], height = n_norm[:,0], width = ourbins[:, 1] - ourbins[:, 0])
p2 = plt.bar(x = ourbins[:,0], height = n_norm[:,1], width = ourbins[:, 1] - ourbins[:, 0],
bottom = n_norm[:,0])
plt.legend(['Response = Yes', 'Response = No'])
plt.title('Normalized Histogram of Age with Response Overlay')
plt.xlabel('Age'); plt.ylabel('Proportion'); plt.show()

bank_train['age_binned'] = pd.cut(x = bank_train['age'], bins = [0, 27, 60.01, 100],
     labels=["Under 27", "27 to 60", "Over 60"], right = False)

crosstab_02 = pd.crosstab(bank_train['age_binned'], bank_train['response'])
crosstab_02.plot(kind='bar', stacked = True,
       title = 'Bar Graph of Age (Binned) with Response Overlay')

crosstab_02_norm = crosstab_02.div(crosstab_02.sum(1), axis = 0)
crosstab_02_norm.plot(kind='bar', stacked = True)

"""Model : is a valid simplified representation of reality

![alt text](https://miro.medium.com/max/640/1*eeIvlwkMNG1wSmj3FR6M2g.gif)

we want to predict someone's heigth based ontheir weigth

H = a * W + b

We are looking for a and b to have the best fit in our data.

what is the best fit: where data is "equally" distributed below and above our regression line.
"""



"""# optimization

every predictive problem can boiled down to an optimization problem, because we want to minimize teh error (or difference between model output and actual outputs)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  


import seaborn as seabornInstance # this is a good library for plotting


from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn import metrics
# %matplotlib inline

url = 'https://raw.githubusercontent.com/ArashVafa/Examples/master/Weather.csv'
dataset = pd.read_csv(url)
dataset.tail()

dataset.plot(x='MinTemp', y='MaxTemp', style='o')  
plt.title('MinTemp vs MaxTemp')  
plt.xlabel('MinTemp')  
plt.ylabel('MaxTemp')  
plt.show()

"""Simple Linear Regression means that we have one independent variable and one dependent variable"""

plt.figure(figsize=(15,10))
plt.tight_layout()
seabornInstance.distplot(dataset['MaxTemp'])

X = dataset['MinTemp'].values.reshape(-1,1)
y = dataset['MaxTemp'].values.reshape(-1,1)

"""# Splitting

We split the dataset in order to gauge the performance of our model by unseen data
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

