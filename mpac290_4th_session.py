# -*- coding: utf-8 -*-
"""MPAc290 4th session.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VxnbGZAdMYZ0V99owkCZS-yTMXzU5GzC

In analytics we have two main approaches to solve problems:
* supervised approach --> which are regression and classification
* unsupervised approach --> Association rules and clustering

Beer and diaper --> Walmart

## Y= mx + b
Where b is the intercept and m is the slope of the line. So basically, the linear regression algorithm gives us the most optimal value for the intercept and the slope (in two dimensions). The y and x variables remain the same, since they are the data features and cannot be changed. The values that we can control are the intercept(b) and slope(m). There can be multiple straight lines depending upon the values of intercept and slope. Basically what the linear regression algorithm does is it fits multiple lines on the data points and returns the line that results in the least error.
This same concept can be extended to cases where there are more than two variables. This is called multiple linear regression. For instance, consider a scenario where you have to predict the price of the house based upon its area, number of bedrooms, the average income of the people in the area, the age of the house, and so on. In this case, the dependent variable(target variable) is dependent upon several independent variables. A regression model involving multiple variables can be represented as:
## y = b0 + m1x1 + m2x2 + m3x3 + … … mnxn
This is the equation of a hyperplane. Remember, a linear regression model in two dimensions is a straight line; in three dimensions it is a plane, and in more than three dimensions, a hyperplane.
In this section, we will see how Python’s Scikit-Learn library for machine learning can be used to implement regression functions. We will start with simple linear regression involving two variables and then we will move towards linear regression involving multiple variables.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
import seaborn as seabornInstance 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn import metrics
# %matplotlib inline

url = 'https://raw.githubusercontent.com/ArashVafa/Examples/master/Weather.csv'
dataset = pd.read_csv(url)

dataset

dataset.shape

dataset.describe()

dataset.plot(x='MinTemp', y='MaxTemp', style='o')  
plt.title('MinTemp vs MaxTemp')  
plt.xlabel('MinTemp')  
plt.ylabel('MaxTemp')  
plt.show()

plt.figure(figsize=(15,10))
plt.tight_layout()
seabornInstance.distplot(dataset['MaxTemp'])

X = dataset['MinTemp'].values.reshape(-1,1)
y = dataset['MaxTemp'].values.reshape(-1,1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

regressor = LinearRegression()  
regressor.fit(X_train, y_train) #training the algorithm

#To retrieve the intercept:
print(regressor.intercept_)
#For retrieving the slope:
print(regressor.coef_)

y_pred = regressor.predict(X_test)

df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})
df

df1 = df.head(25)
df1.plot(kind='bar',figsize=(16,10))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()

plt.scatter(X_test, y_test,  color='gray')
plt.plot(X_test, y_pred, color='red', linewidth=2)
plt.show()

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

"""we have two models one has RMSE of 4 one has RMSE of 5 which one is a better model?

we have two models one has R^2 of 0.4 one has R^2 of 0.5 which one is a better model?

Multiple Linear Regression
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
import seaborn as seabornInstance 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn import metrics
# %matplotlib inline

url2 = 'https://raw.githubusercontent.com/ArashVafa/DESC624/master/winequality.csv'
dataset2 = pd.read_csv(url2)

dataset2.head()

dataset2.shape

dataset2.describe()

X = dataset2[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']].values
y = dataset2['quality'].values

plt.figure(figsize=(15,10))
plt.tight_layout()
seabornInstance.distplot(dataset2['quality'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

regressor = LinearRegression()  
regressor.fit(X_train, y_train)

coeff_df = pd.DataFrame(regressor.coef_)#, X.columns, columns=['Coefficient'])  
coeff_df

"""number 7 is density

it means that a unit increase in density (keeping everything else constant) will deacrese the wine quality by 31
"""

y_pred = regressor.predict(X_test)

df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
df1 = df.head(25)
df1.head()

df1.plot(kind='bar',figsize=(10,8))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

"""# Regression on California Housing Dataset"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

url = 'https://raw.githubusercontent.com/ArashVafa/DESC620/master/housing.csv'

df = pd.read_csv(url)

# Print first 5 rows of the dataframe
df.head()

df['ocean_proximity'].unique()

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.distplot(df['median_house_value'], bins=30)
plt.show()

correlation_matrix = df.corr().round(2)
# annot = True to print the values inside the square
sns.heatmap(data=correlation_matrix, annot=True)

"""assuming we want to predict median house value, choose 3 features in order to predict the target, assuming we want to use a multiple linear regression?"""

X = pd.DataFrame(np.c_[df['housing_median_age'], df['total_rooms']], columns = ['housing_median_age','total_rooms'])
X1 = pd.DataFrame(np.c_[df['housing_median_age']], columns = ['housing_median_age'])
X2 = pd.DataFrame(np.c_[df['total_rooms']], columns = ['total_rooms'])
Y = df['median_house_value']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

lin_model = LinearRegression()
lin_model.fit(X_train, Y_train)

#model evaluation for training set
y_train_predict = lin_model.predict(X_train)
rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))
r2 = r2_score(Y_train, y_train_predict)

print("The model performance for training set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")

# model evaluation for testing set
y_test_predict = lin_model.predict(X_test)
rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))
r2 = r2_score(Y_test, y_test_predict)

print("The model performance for testing set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))

regressor = LinearRegression()  
regressor.fit(X_train, Y_train) #training the algorithm

#To retrieve the intercept:
print(regressor.intercept_)
#For retrieving the slope:
print(regressor.coef_)

y_pred = regressor.predict(X_test)

from mpl_toolkits import mplot3d

import numpy as np
import matplotlib.pyplot as plt

fig = plt.figure()
ax = plt.axes(projection="3d")

z_line = y_train_predict
x_line = X_train['housing_median_age']
y_line = X_train['total_rooms']
ax.plot3D(x_line, y_line, z_line, 'red')

z_points = Y_train
x_points = X_train['housing_median_age']
y_points = X_train['total_rooms']
ax.scatter3D(x_points, y_points, z_points, c =  'blue')#, c=z_points)#, cmap='hsv');

#ax.plot_wireframe(X_test['housing_median_age'], X_test['total_rooms'], y_pred, color='green')
ax.set_xlabel('housing_median_age')
ax.set_ylabel('total_rooms')
ax.set_zlabel('z')

#plt.show()
ax.view_init(210,45)
plt.draw()

!apt-get install libgeos-3.5.0
!apt-get install libgeos-dev
!pip install https://github.com/matplotlib/basemap/archive/master.zip
!pip install pyproj==1.9.6

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from mpl_toolkits.basemap import Basemap

# Extract the data we're interested in
lat = df['latitude'].values
lon = df['longitude'].values
population = df['population'].values
price = df['median_house_value'].values


fig = plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', resolution='h', 
            lat_0=37.5, lon_0=-119,
            width=1E6, height=1.2E6)
m.shadedrelief()
m.drawcoastlines(color='gray')
m.drawcountries(color='gray')
m.drawstates(color='gray')

# 2. scatter city data, with color reflecting population
# and size reflecting area
m.scatter(lon, lat, latlon=True),
          #c=np.log10(population), s=price,
          #cmap='Reds', alpha=0.5)

# 3. create colorbar and legend
#plt.colorbar(label=r'$\log_{10}({\rm population})$')
#plt.clim(3, 7)

# make legend with dummy points
'''for a in [100, 300, 500]:
    plt.scatter([], [], c='k', alpha=0.5, s=a,
                label=str(a) + ' km$^2$')
plt.legend(scatterpoints=1, frameon=False,
           labelspacing=1, loc='lower left');'''

df2 = df[['median_house_value', 'median_income']]

# Import train_test_split function
from sklearn.model_selection import train_test_split
# Split dataset into training set and test set
X_train, X_test = train_test_split(df2, test_size=0.1) # 90% training and 10% test

from sklearn.cluster import KMeans
kmeans = KMeans(5)

kmeans.fit(df2)

df2['predict'] = kmeans.fit_predict(df2)

df2['ocean_proximity'] = df['ocean_proximity']

df2['ocean_proximity_numerical'] = df2['ocean_proximity']

df2['ocean_proximity_numerical'] = df2['ocean_proximity_numerical'].replace({'NEAR BAY': 0})
df2['ocean_proximity_numerical'] = df2['ocean_proximity_numerical'].replace({'<1H OCEAN': 1})
df2['ocean_proximity_numerical'] = df2['ocean_proximity_numerical'].replace({'INLAND': 2})
df2['ocean_proximity_numerical'] = df2['ocean_proximity_numerical'].replace({'NEAR OCEAN': 3})
df2['ocean_proximity_numerical'] = df2['ocean_proximity_numerical'].replace({'ISLAND': 4})

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from mpl_toolkits.basemap import Basemap

# Extract the data we're interested in
lat = df['latitude'].values
lon = df['longitude'].values
population = df['population'].values
price = df['median_house_value'].values


fig = plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', resolution='h', 
            lat_0=37.5, lon_0=-119,
            width=1E6, height=1.2E6)
m.shadedrelief()
m.drawcoastlines(color='gray')
m.drawcountries(color='gray')
m.drawstates(color='gray')

# 2. scatter city data, with color reflecting population
# and size reflecting area
'''m.scatter(lon, lat, latlon=True,
          c=np.log10(population), s=price,
          cmap='Reds', alpha=0.5)'''

m.scatter(lon, lat, latlon=True,
          c=np.log10(population),
          cmap='Reds', alpha=0.5)

# Extract the data we're interested in
lat = df['latitude'].values
lon = df['longitude'].values
income = df2['median_income'].values
price = df['median_house_value'].values
predict = df2['predict'].values


fig = plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', resolution='h', 
            lat_0=37.5, lon_0=-119,
            width=1E6, height=1.2E6)
m.shadedrelief()
m.drawcoastlines(color='gray')
m.drawcountries(color='gray')
m.drawstates(color='gray')

# 2. scatter city data, with color reflecting population
# and size reflecting area
'''m.scatter(lon, lat, latlon=True,
          c=np.log10(population), s=price,
          cmap='Reds', alpha=0.5)'''

m.scatter(lon, lat, latlon=True,
          c=np.log10(predict), alpha=0.5)

"""# SQL

Structured Query Language

database is an organized collection of interrelated data stored in an electronic format.

Relational Database model: organizes the data into tables where each row holds a tuple
"""

a = ("2", 12, "Arash")

"""Database Management System (DBMS)

Relational Database Management System or RDBMS --> MySQL, Postgres, SQL server 


SQLite https://www.sqlite.org/index.html
"""

import sqlite3

# create new database
conn = sqlite3.connect('.\sql_db\Demo_table.db')

# create Cursor to execute queries
cur = conn.cursor()

print('Databse created.')

# save changes
conn.commit()
print('Changes saved.')

# close database connection
conn.close()
print('Connection closed.')

# connect to existing database
conn = sqlite3.connect('.\sql_db\Demo_table.db')
cur = conn.cursor()

# create table in database
cur.execute('''CREATE TABLE CUSTOMER(
                User_ID INTEGER PRIMARY KEY NOT NULL,
                Product_ID INTEGER NOT NULL,
                Name TEXT NOT NULL,
                Gender TEXT NOT NULL,
                AGE INTEGER NOT NULL,
                CITY TEXT);
                ''')

# commit and save changes to database
conn.commit()

cur.execute('''Insert Into Customer ('User_ID','Product_ID','Name','Gender','AGE','CITY') Values (1006, 3, 'Princess Diana', 'Female', 28, 'Amazons');''')

# Execute multiple commands at once
cur.executescript('''Insert Into CUSTOMER Values
                (1005, 3, 'Clark Kent', 'Male', 36, 'Metropolis');
                
                Insert Into CUSTOMER Values
                (1003, 4, 'Bruce Wayne', 'Male', 39, 'Gotham City');
                
                ''')

# Insert maultiple values into table at once
customers = [(1004, 2, 'John Wick', 'Male', 32, 'New York'),
         (1001, 1, 'Tony Stark', 'Male', 35, 'New York'),
         (1002, 3, 'Gordon Ramsey', 'Male', 38, 'London')
            ]
cur.executemany('Insert Into CUSTOMER Values (?,?,?,?,?,?)', customers)

# Fetch all rows of query result
cur.execute('SELECT * FROM CUSTOMER;').fetchone()

# iterate over the rows 
for row in cur.execute('SELECT Name FROM CUSTOMER;'):
    print(row)

# Fetch all rows of query result which returns a list
cur.execute('SELECT * FROM CUSTOMER;').fetchall()

import pandas as pd
import sqlite3

# read csv files
#df_train = pd.read_csv('./train_food/train.csv')
#df_meal = pd.read_csv('./train_food/meal_info.csv')
#df_center = pd.read_csv('./train_food/fulfilment_center_info.csv')

# connect to database
conn = sqlite3.connect('.\sql_db\train.db')
cur = conn.cursor()

# load dataframes into database
dataset.to_sql("train", conn)

df = pd.read_sql_query("select * from train;", conn)
df.head()

# WHERE clause
df = pd.read_sql_query('''Select * from train 
                        Where STA!='10001'; ''', conn)
df

# GROUPBY statement
df = pd.read_sql_query('''Select Count(STA) from train
                        Group by Snowfall;''',conn)
df

"""<table>
<tr>
<th> SQL </th>
<th> Python </th>
</tr>


<tr>
<td>
<pre>
SELECT name
FROM titanic_test_data
</pre>
</td>

<td>
<pre>
titanic_df["name"]
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT *
FROM titanic_test_data
LIMIT 5
</pre>
</td>

<td>
<pre>
titanic_df.head(5)
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT DISTINCT age
FROM titanic_test_data
</pre>
</td>

<td>
<pre>
titanic_df["age"].unique()
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT COUNT(DISTINCT age)
FROM titanic_test_data
</pre>
</td>

<td>
<pre>
len(titanic_df["age"].unique())
</pre>
</td>
</tr>


</table>

<table>
<tr>
<th> SQL </th>
<th> Python </th>
</tr>


<tr>
<td>
<pre>
SELECT *
FROM titanic_test_data
WHERE pclass = 1
</pre>
</td>

<td>
<pre>
titanic_df[titanic_df.pclass == 1]
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT *
FROM titanic_test_data
WHERE pclass = 1
OR pclass = 2
</pre>
</td>

<td>
<pre>
titanic_df[(titanic_df.pclass == 1) | 
(titanic_df.pclass == 2)]
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT *
FROM titanic_test_data
WHERE pclass IN (1,2)
</pre>
</td>

<td>
<pre>
titanic_df[titanic_df.pclass.isin([1,2])]
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT name
FROM titanic_test_data
WHERE pclass = 1 
AND gender = "male"
</pre>
</td>

<td>
<pre>
titanic_df[(titanic_df.pclass == 1) 
& (titanic_df.gender == "male")]["name"] 
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT name, age
FROM titanic_test_data
WHERE pclass NOT IN (1,2)
</pre>
</td>

<td>
<pre>
titanic_df[~titanic_df.pclass.isin([1,2])] 
[["name","age"]]
</pre>
</td>
</tr>


</table>

<table>
<tr>
<th> SQL </th>
<th> Python </th>
</tr>


<tr>
<td>
<pre>
SELECT
pclass,
gender,
COUNT(*)
FROM titanic_test_data
GROUP BY 1,2
</pre>
</td>

<td>
<pre>
titanic_df.groupby(["pclass","gender"]).size()
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT
pclass,
gender,
COUNT(*)
FROM titanic_test_data
GROUP BY 1,2
ORDER BY 3 DESC
</pre>
</td>

<td>
<pre>
titanic_df.groupby(["pclass","gender"])
.size().sort_values(ascending=False) 
</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT
name,
pclass,
gender
FROM titanic_test_data
ORDER BY 1, 2 DESC
</pre>
</td>

<td>
<pre>
titanic_df.sort_values(["name","pclass"],
ascending=[True,False])
[["name","pclass","gender"]] 

</pre>
</td>
</tr>


<tr>
<td>
<pre>
SELECT
pclass,
gender,
SUM(fare)
FROM titanic_test_data
GROUP BY 1,2
</pre>
</td>

<td>
<pre>
titanic_df.groupby(["pclass","gender"]).sum()["fare"]
</pre>
</td>
</tr>


</table>

<table>
<tr>
<th> SQL </th>
<th> Python </th>
</tr>


<tr>
<td>
<pre>
SELECT
MIN(age) AS min,
MAX(age) AS max,
AVG(age) AS mean,
APPROX_QUANTILES(age, 100)[OFFSET(50)] AS median
FROM titanic_test_data
</pre>
</td>

<td>
<pre>
titanic_df.agg(
{'age': ['min', 'max', 
'mean', 'median']})
</pre>
</td>
</tr>



</table>

# regression on another dataset
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt 

import pandas as pd  
import seaborn as sns 

# %matplotlib inline

from sklearn.datasets import load_boston
boston_dataset = load_boston()

boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)
boston.head()

boston['MEDV'] = boston_dataset.target

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.distplot(boston['MEDV'], bins=30)
plt.show()

boston.describe()

correlation_matrix = boston.corr().round(2)
# annot = True to print the values inside the square
sns.heatmap(data=correlation_matrix, annot=True)

"""The correlation coefficient ranges from -1 to 1. If the value is close to 1, it means that there is a strong positive correlation between the two variables. When it is close to -1, the variables have a strong negative correlation."""

plt.figure(figsize=(20, 5))

features = ['LSTAT', 'RM']
target = boston['MEDV']

for i, col in enumerate(features):
    plt.subplot(1, len(features) , i+1)
    x = boston[col]
    y = target
    plt.scatter(x, y, marker='o')
    plt.title(col)
    plt.xlabel(col)
    plt.ylabel('MEDV')

X = pd.DataFrame(np.c_[boston['LSTAT'], boston['RM']], columns = ['LSTAT','RM'])
Y = boston['MEDV']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

lin_model = LinearRegression()
lin_model.fit(X_train, Y_train)

# model evaluation for training set
y_train_predict = lin_model.predict(X_train)
rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))
r2 = r2_score(Y_train, y_train_predict)

print("The model performance for training set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")

# model evaluation for testing set
y_test_predict = lin_model.predict(X_test)
rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))
r2 = r2_score(Y_test, y_test_predict)

print("The model performance for testing set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))

url = 'http://archive.ics.uci.'